[tools]
uv = "0.8.17"

[tasks]
setup = { description = "Deps(frozen) + git hooks", run = "uv sync --frozen && uv run pre-commit install --install-hooks --hook-type pre-commit --hook-type pre-push" }
dev = { description = "Run app", run = "uv run streamlit run app.py" }
sample = { description = "Generate 7-day SAR with visible spikes under logs/sample/saYYYYMMDD", run = """
bash -lc '
set -e
ROOT=logs/sample
mkdir -p "$ROOT"

if ! command -v sar >/dev/null; then
  echo "sar not found; attempting fallback copy from samples/sar_v12.dat"
  if [ -f samples/sar_v12.dat ]; then
    for i in $(seq 0 6); do D=$(date -d "-$i day" +%Y%m%d); cp -f samples/sar_v12.dat "$ROOT/sa$D"; echo "Copied samples/sar_v12.dat -> $ROOT/sa$D"; done
    exit 0
  else
    echo "No sar binary and no samples/sar_v12.dat available" >&2
    exit 1
  fi
fi

for i in $(seq 0 6); do
  D=$(date -d "-$i day" +%Y%m%d)
  OUT="$ROOT/sa$D"
  echo "Collecting $OUT (10s with synthetic spikes)"
  (sar -o "$OUT" 1 10 >/dev/null 2>&1) &
  SAR_PID=$!
  # CPU spike ~3s
  sleep 2
  (yes > /dev/null) & P1=$!; sleep 3; kill $P1 2>/dev/null || true
  # Disk spike
  dd if=/dev/zero of="$ROOT/io_$D.bin" bs=1M count=64 oflag=direct 2>/dev/null || true
  rm -f "$ROOT/io_$D.bin"
  # Short CPU spike again
  (yes > /dev/null) & P2=$!; sleep 2; kill $P2 2>/dev/null || true
  wait $SAR_PID 2>/dev/null || true
done
'
""" }
fmt = { description = "Format code", run = "uv run ruff format ." }
lint = { description = "Lint code", run = "uv run ruff check ." }
fix = { description = "Apply lint fixes", run = "uv run ruff check . --fix" }
type = { description = "Type-check", run = "uv run pyright" }
check = { description = "Format(check)+Lint+Type", run = "uv run ruff format --check . && uv run ruff check . && uv run pyright" }
test = { description = "Run tests", run = "uv run pytest -q" }
clean = { description = "Clean artifacts (logs + caches)", run = "bash -lc 'rm -rf logs/* 2>/dev/null || true; find . -name __pycache__ -type d -exec rm -rf {} +'" }
precommit = { description = "Run pre-commit all", run = "uv run pre-commit run --all-files" }
[tasks."sample:csv"]
description = "Generate dummy CSV bundle under logs/sample/csv/YYYY-MM-DD/{cpu,memory,disk,network,fs}.csv"
run = """
bash -lc '
set -e
ROOT=logs/sample/csv
mkdir -p "$ROOT"

gen_cpu() {
  D="$1"; DIR="$ROOT/$D"; mkdir -p "$DIR"
  python3 - <<PY
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
start = datetime.strptime("$D 12:00:00", "%Y-%m-%d %H:%M:%S")
t = pd.date_range(start, periods=30, freq="S")
cpu = ["all"]*30
user = np.zeros(30); user[5:10]=np.linspace(10,80,5); user[10:15]=np.linspace(80,10,5)
system = np.zeros(30); system[20:25]=50
iowait = np.zeros(30)
idle = 100 - user - system - iowait
pd.DataFrame({"timestamp":t, "cpu":cpu, "user":user, "system":system, "iowait":iowait, "idle":idle}).to_csv("$DIR/cpu.csv", index=False)
PY
}

gen_mem() {
  D="$1"; DIR="$ROOT/$D"; mkdir -p "$DIR"
  python3 - <<PY
import pandas as pd
from datetime import datetime, timedelta
import numpy as np
start = datetime.strptime("$D 12:00:00", "%Y-%m-%d %H:%M:%S")
t = pd.date_range(start, periods=30, freq="S")
memused_pct = np.linspace(40,60,30)
cached = np.linspace(1000,1500,30)
buffers = np.linspace(200,300,30)
pd.DataFrame({"timestamp":t, "memused_pct":memused_pct, "cached":cached, "buffers":buffers}).to_csv("$DIR/memory.csv", index=False)
PY
}

gen_disk() {
  D="$1"; DIR="$ROOT/$D"; mkdir -p "$DIR"
  python3 - <<PY
import pandas as pd
from datetime import datetime
import numpy as np
start = datetime.strptime("$D 12:00:00", "%Y-%m-%d %H:%M:%S")
t = pd.date_range(start, periods=30, freq="S")
dev = ["sda"]*30
tps = np.zeros(30); tps[8:12]=[50,150,50,10]
rkB_s = np.zeros(30); rkB_s[8:12]=[0,4096,0,0]
wkB_s = np.zeros(30); wkB_s[20:24]=[0,8192,0,0]
await = np.zeros(30); await[8:12]=[2,50,2,1]
util_pct = np.zeros(30); util_pct[8:12]=[10,95,20,5]
pd.DataFrame({"timestamp":t, "dev":dev, "tps":tps, "rkB_s":rkB_s, "wkB_s":wkB_s, "await":await, "util_pct":util_pct}).to_csv("$DIR/disk.csv", index=False)
PY
}

gen_net() {
  D="$1"; DIR="$ROOT/$D"; mkdir -p "$DIR"
  python3 - <<PY
import pandas as pd
from datetime import datetime
import numpy as np
start = datetime.strptime("$D 12:00:00", "%Y-%m-%d %H:%M:%S")
t = pd.date_range(start, periods=30, freq="S")
iface = ["eth0"]*30
rxkB_s = np.zeros(30); rxkB_s[15:18]=[0,512,0]
txkB_s = np.zeros(30); txkB_s[15:18]=[0,2048,0]
pd.DataFrame({"timestamp":t, "iface":iface, "rxkB_s":rxkB_s, "txkB_s":txkB_s}).to_csv("$DIR/network.csv", index=False)
PY
}

gen_fs() {
  D="$1"; DIR="$ROOT/$D"; mkdir -p "$DIR"
  python3 - <<PY
import pandas as pd
from datetime import datetime
import numpy as np
start = datetime.strptime("$D 12:00:00", "%Y-%m-%d %H:%M:%S")
t = pd.date_range(start, periods=5, freq="min")
filesystem = ["/dev/sda1"]*len(t)
mb_free = [950000,940000,930000,920000,910000]
fsused_pct = [5,6,7,8,9]
pd.DataFrame({"timestamp":t, "filesystem":filesystem, "mb_free":mb_free, "fsused_pct":fsused_pct}).to_csv("$DIR/fs.csv", index=False)
PY
}

for i in $(seq 0 6); do
  D=$(date -d "-$i day" +%Y-%m-%d)
  gen_cpu "$D"; gen_mem "$D"; gen_disk "$D"; gen_net "$D"; gen_fs "$D"
done
'
"""
