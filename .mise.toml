[tools]
uv = "0.8.17"

[tasks]
setup = { description = "Deps(frozen) + git hooks", run = "uv sync --frozen && uv run pre-commit install --install-hooks --hook-type pre-commit --hook-type pre-push" }
dev = { description = "Run app", run = "uv run streamlit run app.py" }
sample = { description = "Generate 7-day SAR with visible spikes under logs/sample/saYYYYMMDD", run = """
bash -lc '
set -e
ROOT=logs/sample
mkdir -p "$ROOT"

if ! command -v sar >/dev/null; then
  echo "sar not found; attempting fallback copy from samples/sar_v12.dat"
  if [ -f samples/sar_v12.dat ]; then
    for i in $(seq 0 6); do D=$(date -d "-$i day" +%Y%m%d); cp -f samples/sar_v12.dat "$ROOT/sa$D"; echo "Copied samples/sar_v12.dat -> $ROOT/sa$D"; done
    exit 0
  else
    echo "No sar binary and no samples/sar_v12.dat available" >&2
    exit 1
  fi
fi

for i in $(seq 0 6); do
  D=$(date -d "-$i day" +%Y%m%d)
  OUT="$ROOT/sa$D"
  echo "Collecting $OUT (10s with synthetic spikes)"
  (sar -o "$OUT" 1 10 >/dev/null 2>&1) &
  SAR_PID=$!
  # CPU spike ~3s
  sleep 2
  (yes > /dev/null) & P1=$!; sleep 3; kill $P1 2>/dev/null || true
  # Disk spike
  dd if=/dev/zero of="$ROOT/io_$D.bin" bs=1M count=64 oflag=direct 2>/dev/null || true
  rm -f "$ROOT/io_$D.bin"
  # Short CPU spike again
  (yes > /dev/null) & P2=$!; sleep 2; kill $P2 2>/dev/null || true
  wait $SAR_PID 2>/dev/null || true
done
'
""" }
fmt = { description = "Format code", run = "uv run ruff format ." }
lint = { description = "Lint code", run = "uv run ruff check ." }
fix = { description = "Apply lint fixes", run = "uv run ruff check . --fix" }
type = { description = "Type-check", run = "uv run pyright" }
check = { description = "Format(check)+Lint+Type", run = "uv run ruff format --check . && uv run ruff check . && uv run pyright" }
test = { description = "Run tests", run = "uv run pytest -q" }
clean = { description = "Clean artifacts (logs + caches)", run = "bash -lc 'rm -rf logs/* 2>/dev/null || true; find . -name __pycache__ -type d -exec rm -rf {} +'" }
precommit = { description = "Run pre-commit all", run = "uv run pre-commit run --all-files" }
[tasks."sample:csv"]
description = "Generate per-resource CSV under logs/sample/csv/YYYY-MM-DD/{cpu,memory,disk,network,fs}.csv (last 7 days)"
run = """
bash -lc '
set -e
ROOT=logs/sample/csv
mkdir -p "$ROOT"
for i in $(seq 0 6); do
  D=$(date -d "-$i day" +%Y-%m-%d)
  DIR="$ROOT/$D"
  mkdir -p "$DIR"
  echo "Generating $DIR/*.csv"
  python3 - <<PY
import pandas as pd
import numpy as np
from datetime import datetime
D = "$D"
start = datetime.strptime(f"{D} 12:00:00", "%Y-%m-%d %H:%M:%S")
t = pd.date_range(start, periods=30, freq="s")

# CPU
cpu = pd.DataFrame({
  "timestamp": t,
  "cpu": ["all"]*30,
  "user": np.r_[np.zeros(5), np.linspace(10,80,5), np.linspace(80,10,5), np.zeros(15)],
  "system": np.r_[np.zeros(20), np.full(5,50), np.zeros(5)],
  "iowait": np.zeros(30),
  "idle": 0.0,
})
cpu["idle"] = 100 - cpu["user"] - cpu["system"] - cpu["iowait"]
cpu.to_csv(f"$DIR/cpu.csv", index=False)

# Memory
mem = pd.DataFrame({
  "timestamp": t,
  "memused_pct": np.linspace(40,60,30),
  "cached": np.linspace(1000,1500,30),
  "buffers": np.linspace(200,300,30),
})
mem.to_csv(f"$DIR/memory.csv", index=False)

# Disk
disk = pd.DataFrame({
  "timestamp": t,
  "dev": ["sda"]*30,
  "tps": np.r_[np.zeros(8), [50,150,50,10], np.zeros(18)],
  "rkB_s": np.r_[np.zeros(8), [0,4096,0,0], np.zeros(18)],
  "wkB_s": np.r_[np.zeros(20), [0,8192,0,0], np.zeros(6)],
  "await": np.r_[np.zeros(8), [2,50,2,1], np.zeros(18)],
  "util_pct": np.r_[np.zeros(8), [10,95,20,5], np.zeros(18)],
})
disk.to_csv(f"$DIR/disk.csv", index=False)

# Network
net = pd.DataFrame({
  "timestamp": t,
  "iface": ["eth0"]*30,
  "rxkB_s": np.r_[np.zeros(15), [0,512,0], np.zeros(12)],
  "txkB_s": np.r_[np.zeros(15), [0,2048,0], np.zeros(12)],
})
net.to_csv(f"$DIR/network.csv", index=False)

# Filesystem capacity
fs_t = pd.date_range(start, periods=5, freq="min")
fs = pd.DataFrame({
  "timestamp": fs_t,
  "filesystem": ["/dev/sda1"]*len(fs_t),
  "mb_free": [950000,940000,930000,920000,910000],
  "fsused_pct": [5,6,7,8,9],
})
fs.to_csv(f"$DIR/fs.csv", index=False)
PY
done
'
"""
